{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Automation Project\n",
    "\n",
    "This is your last project for this semester! This one has three goals:\n",
    "- To have you create a pipeline of Machine Learning for use in a real project, the one you could have done for the Hackaton (if it had been better set).\n",
    "- Link blocks of knowledge you already have, and consolidate it.\n",
    "- Make you able to create your own project, almost from A to Z.\n",
    "\n",
    "This project is divided in 3 or 4 stages. Each stage will be graded. At the end of each stage, I will give you the solution of the stage so you can follow up on the next one.\n",
    "\n",
    "## Stage 1: Create database\n",
    "\n",
    "I give you two data sources :\n",
    "* The [Movie Database API](https://developers.themoviedb.org/3/getting-started/introduction). Search for all the movies containing `cat`.\n",
    "* The [IMDB Kaggle dataset](https://www.kaggle.com/PromptCloudHQ/imdb-data#IMDB-Movie-Data.csv). Keep only films that have the letters `cat` in their description (it does not have to be a single word, so `Catastrophe` should match)\n",
    "\n",
    "You read the data and transform it to be able to store it in a Database of your choice. \n",
    "\n",
    "A SQL db or Neo4J would be the easiest to set up, but I will totally approve the choice of Elastic Search or Hadoop. You can even use MongoDB if you'd like.\n",
    "\n",
    "It's okay to have the same movie in both sources - keep all the infos, do not remove one of them.\n",
    "\n",
    "Of course, you should process and store this data on your database fully in Python.\n",
    "\n",
    "You can use a DataFrame to help you aggregate the data.\n",
    "\n",
    "* **Take a screenshot** of your database results and send it alongside your code.\n",
    "\n",
    "* **Deadline**: Tuesday, 5th of May, 23h42.\n",
    "\n",
    "\n",
    "## Stage 2: Make training and prediction available on API\n",
    "\n",
    "Read the data from your database.\n",
    "\n",
    "Step 1. You have three functions to write:\n",
    "\n",
    "1. `get_model()` will return a untrained scikit-learn model.\n",
    "* The second one will use train this model for prediction, using database data.\n",
    "* The third one will use the trained model to predict.\n",
    "\n",
    "We don't care about the precision of the model for now, don't spend time thinking about it.\n",
    "\n",
    "The model has to predict the movie's title based (at least) on its description/overview. (It can be a very bad prediction, just make sure you get a description/overview in input and return a movie title)\n",
    "\n",
    "When you are done with those functions, you can start the next tasks:\n",
    "\n",
    "Step 1. Create a Flask API with two endpoints:\n",
    "\n",
    "1. The first one is `GET /model/train`. It will call the second function, that trains the model based on database data.\n",
    "* The second one is `POST /model/predict`. It will take a sample of features as data, use the third function to predict the target and return the result.\n",
    "\n",
    "* **Deadline**: Tuesday, 12th of May, 23h42.\n",
    "\n",
    "\n",
    "## Stage 3: Make more available on API\n",
    "\n",
    "Your model and datasets needs to live. How?\n",
    "\n",
    "Add two endpoints to your Flask API:\n",
    "* `POST /data` to add a new sample (features + target) to your training dataset.\n",
    "\n",
    "This way, you should be able to run the Train endpoint and see your model update.\n",
    "\n",
    "* `GET /model/train_test` to evaluate your model from `get_model()`.\n",
    "\n",
    "This function have to:\n",
    "1. Read the data\n",
    "- Transform it into X and y\n",
    "- Use train_test_split to get X_train, X_test, y_train y_test\n",
    "- Train the model from `get_model()` on X_train, y_train\n",
    "- Compare your predictions on X_test with y_test\n",
    "\n",
    "This make you able to run `GET /model/train_test` after changing the content of `get_model()` function and evaluate the MAE evolution easily.\n",
    "\n",
    "* **Deadline**: Tuesday, 19th of May, 23h42.\n",
    "\n",
    "\n",
    "## Stage 4 (Bonus):\n",
    "\n",
    "Optional stage, only if you feel like it. Select one of more of the upgrade you would like to do:\n",
    "\n",
    "* Make your API RESTful.\n",
    "* Improve the text treament so you have more features to predict movie's names.\n",
    "* Improve your model to predict movie's names.\n",
    "\n",
    "\n",
    "* **Deadline**: Tuesday, 26th of May, 23h42.\n",
    "\n",
    "\n",
    "# Constraints\n",
    "\n",
    "* Send your code in .ipynb or .py files, as you wish.\n",
    "* **Take a screenshot** of your database results.\n",
    "* Send your `.env` file.\n",
    "* Send your work to my inbox laure.daumal@ext.devinci.fr\n",
    "* Respect the deadline for each stage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
